<!DOCTYPE html>
<html lang="en">
<head>
<title>Maggie's Codes</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<style>
*{
    box-sizing: border-box;
}

body {
    margin: 0;
}

/* Style the header */
.header {
    font-family: Arial, Helvetica, sans-serif;
    font-size: 25px;
    font-weight: bold;
    letter-spacing: 1.4px;
    background-color: #f1f1f1;
    padding: 10px;
    text-align: center;
}

H2 {
    font-family: Arial, Helvetica, sans-serif;
    font-size: 15px;
    font-weight: normal;
    letter-spacing: 1.2px;
    color: #009900;
}
tab2 { 
    padding-left: 2em; 
}
P {
    font-family: Arial, Helvetica, sans-serif;
    font-size: 15px;
    color: #555555;
    line-height: 1.5;
    letter-spacing: .25px;
}
/* Style the top navigation bar */
.topnav {
    font-family: Arial, Helvetica, sans-serif;
    font-size: 18px;
    font-weight: normal;
    letter-spacing: 1.2px;
    color: #000000;
    overflow: hidden;
    background-color: #f9f9f9;
}

/* Style the topnav links */
.topnav a {
    float:left;
    display: block;
    color: #000000;
    text-align:middle;
    padding: 14px 16px;
    text-decoration: none;
}

/* Change color on hover */
.topnav a:hover {
    background-color: #ddd;
    color: #009900;
}
/* Create three unequal columns that floats next to each other */
.column {
    float: left;
    padding: 10px;
}

/* Left and right column */
.column.side {
    width: 15%;
}

/* Middle column */
.column.middle {
    width: 70%;
}

/* Clear floats after the columns */
.row:after {
    content: "";
    display: table;
    clear: both;
}

/* Responsive layout - makes the three columns stack on top of each other instead of next to each other */
@media (max-width: 800px) {
    .column.side, .column.middle {
        width: 100%;
    }
}

.dropbtn {
    font-family: Arial, Helvetica, sans-serif;
    font-size: 12px;
    font-weight: normal;
    letter-spacing: 1.2px;
    background-color: #f9f9f9;
    border-bottom: solid 1px #f9f9f9;
    text-transform: uppercase;
    color: black;
    padding: 8px;
    font-size: 16px;
    border: none;
    cursor: pointer;
}

.dropdown {
    position: relative;
    display: inline-block;
}

.dropdown-content {
    display: none;
    position: absolute;
    background-color: #f9f9f9;
    min-width: 160px;
    box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.2);
    z-index: 1;
}

.dropdown-content a {
    font-family: Arial, Helvetica, sans-serif;
    font-size: 12px;
    font-weight: normal;
    letter-spacing: 1.2px;
    color: black;
    padding: 12px 16px;
    text-decoration: none;
    display: block;
}

.dropdown-content a:hover {background-color: #f1f1f1}

.dropdown:hover .dropdown-content {
    display: block;
}

.dropdown:hover .dropbtn {
    background-color: #3e8e41;
}

table, th, td {
    border: 1px solid black;
}

a:link {
    color: #3e8e41;
    background-color: transparent;
    text-decoration: none;
}
a:visited {
    color: #3e8e41;
    background-color: transparent;
    text-decoration: none;
}
a:hover {
    color: #006400;
    background-color: transparent;
    text-decoration: underline;
}
a:active {
    color: #3e8e41;
    background-color: transparent;
    text-decoration: none;
}
</style>
</head>
<body>

<div class="header">
  <h1>Project Logs </h1>
</div>
<div class="topnav">
  <a href="index.html">Home</a>
  <a href="about_me.html">About Me</a>
  <a href="project_logs.html">Project Documentation</a>
  <a href="interests.html">Interests</a>
</div>

<div class="row">
  <div class="column side">
    <h2>Projects List</h2>
    <p><div class="dropdown">
  <button class="dropbtn">Simple Functions</button>
  <div class="dropdown-content">
    <a href="Basic_Functions/compare_sorting.cpp">Compare Sorting Algorithms</a> 
    <a href="Basic_Functions/subset.cpp">Subset </a> 
    <a href="Basic_Functions/dynamic.cpp">Dynamic Function example</a>
    <a href="Basic_Functions/Algorithms.py">Recursive Algorithms</a>
    <a href="Basic_Functions/sierpinksi_gasket.py">Recursive Sierpinksi gasket</a>
  </div>
</div></p>

<p><div class="dropdown">
  <button class="dropbtn">Google Code Jam</button>
  <div class="dropdown-content">
    <a href="https://code.google.com/codejam/contest/544101/dashboard"> Connect-K Assignment Link </a> 
    <a href="Google_Code_Jam/Board.cpp">Board Class</a> 
    <a href="Google_Code_Jam/Board.h">Board Header File</a> 
    <a href="Google_Code_Jam/mainBoard.cpp">Board main driver</a> 
    <a href="Google_Code_Jam/reverse.cpp">Reverse</a> <br>
    <a href="Google_Code_Jam/AlienLanguage.cpp">Alien Language</a>
    <a href="Google_Code_Jam/Numbers.cpp">Numbers</a>
    <a href="Google_Code_Jam/MinimumScalarProduct.cpp">Minimum Scalar Product</a>
  </div>
</div></p>

<p><div class="dropdown">
  <button class="dropbtn">Systems Programming</button>
  <div class="dropdown-content">
    <a href="Systems_Programming/uniq.c">Uniq command</a>
    <a href="Systems_Programming/runsim.c">Running child processes</a>
    <a href="Systems_Programming/my_grep.c">Grep command</a>
    <a href="Systems_Programming/pipe.c">Pipe example</a>
    <a href="Systems_Programming/my_nohup.c">Signals </a>
  </div>
</div></p>

<p><div class="dropdown">
  <button class="dropbtn">Mirai Project </button>
  <div class="dropdown-content">
    <a href="MiraiSecurityProject.pdf">Mirai execution report</a>
  </div>
</div></p>

<p><div class="dropdown">
  <button class="dropbtn">Simple Shapes CNN </button>
  <div class="dropdown-content">
    <a href="Simple_Shapes_CNN/proposal.pdf">Neural Network Concept Proposal</a>
    <a href="Simple_Shapes_CNN/draw.py">Drawing random shapes (Dataset Generator)</a>
    <a href="Simple_Shapes_CNN/pickletestcats.py">Creating pickle files</a>
    <a href="Simple_Shapes_CNN/merge_files.py">Merging pickle files</a>
    <a href="Simple_Shapes_CNN/load_merged_files.py">Pickle loader to CNN</a>
    <a href="Simple_Shapes_CNN/cnn_sobel_main.py">Sobel Algorithm for Edge & Contour Detection</a>
    <a href="Simple_Shapes_CNN/save_pickle_images.py">Reduce image size</a>
    <a href="Simple_Shapes_CNN/cnn_copy_sobel_test.py">CNN loader</a>
    <a href="Simple_Shapes_CNN/cnn_sobel_inception.py">CNN Inception Example</a>
    <a href="Simple_Shapes_CNN/test_model.py">Test trained model</a>
    <a href="Simple_Shapes_CNN/googlecloud_config_cnn.txt">Google Cloud Configuration</a> 
  </div>
</div></p>

</div>


  <div class="column middle">
  <div style="width:800px;height:700px;line-height:1.2em;overflow:auto;padding:0px;">
    <h2>Project Logs for Simple Shapes using Convolutional Neural Network project</h2>
    <p>
    <p><div class="dropdown">
  <button class="dropbtn">Project Logs</button>
  <div class="dropdown-content"> 
    <a href="Simple_Shapes_CNN/logs_text.pdf">Google Cloud Logs</a>
    <a href="Simple_Shapes_CNN/project_logs.pdf">Project Logs</a>
    <a href="Simple_Shapes_CNN/interim_status_report.pdf">Interim Status Report</a>
    <a href="Simple_Shapes_CNN/nn_architecture.pdf">CNN design & Research</a>
    <a href="Simple_Shapes_CNN/interim_status_report2.pdf">Interim Status Report II</a>
    <a href="sobel_crop.pdf">Sobel Algorithm Illustrations</a>
    <a href="Simple_Shapes_CNN/Final_Report.pdf">Project Final Report</a>
    <a href="Simple_Shapes_CNN/sobel_copy.pdf">Description of Project</a>
    <a href="Simple_Shapes_CNN/google_cloud_vm.pdf">Virtual Machine (Ubuntu Xenial) Project Logs</a>
    <a href="Simple_Shapes_CNN/training_chart.pdf">Training Chart</a>
    <a href="Simple_Shapes_CNN/training_output_documentation.pdf">Training Output</a>
    </div>
  </div><p><h2><a href="cnnproject_details.html">Project Details</a></h2>
    </p>
   <p> Introduction: <br>
	<tab2> Pattern classification and recognition, which is a field of machine learning, 
	has been one of the most challenging tasks for a computer. This is because computers 
	do not learn the same way as humans. Humans can generalize and have temporary memory, 
	making it difficult for machines to be hard-coded in the natural technicalities of the human brain. 
	However, neural networks embody a similar organization of how neurons interact with each other. 
	Each weight of single neuron in the neural network represents how strong the neuron’s 
	knowledge is about the data input. The neurons are connected to each other in each layer 
	and in between layers, which is also called a fully connected layer. As each input data 
	is propagated forward through the hidden layers of the neural network, there are activation 
	functions which acts as a summation of the input values multiplied by the weights for the 
	learning features to be feed into the next layer. As it reaches the last layer output, 
	which is the main classifier because it determines the probability of the class, the 
	data is backpropagated using sophisticated multivariable calculus to update the weights. <br> 
	<tab2> Without the weight updates, the neural network would not be able to learn. Each 
	epoch describes a single forward and backward pass. Since the project is about classifying 
	images of simple shapes, which includes circle, triangle, rectangle and square, a convolutional 
	neural network will be implemented. A convolutional neural network do not need feature extraction 
	in the preprocessing of the input images. The layers of the convolutional neural network act as 
	a feature detector by extracting actual pixels from the data image, gathering features from 
	filters and maxpooling. Then, the convolutional neural network will be connected to a traditional 
	fully connected neural network to perform image classification. </p>

   <p> Problem, Solution and Enhancements: <br>
	<tab2> There are a lot of problems that need to be solved in the simple shapes 
	image classification project. The hardest part of this simple shapes image classification 
	problem is to be able to get the convolutional neural network to generalize well without 
	overfitting or underfitting the network model. It is hard to generalize because the input 
	data is never perfect, and it is redundant for the convolutional neural network to process 
	background data without the class object. The input data is created by using Python’s Cairo 
	module, where single shapes of each class is drawn on random locations, rotations and scales 
	on the 300 pixels by 300 pixels image. <br>
	<tab2> The final solution to deal with the unnecessary background data is to use the Sobel 
	algorithm to detect edges, crop the image, and paste it on the 200 pixels by 200 pixels 
	canvas with the same background color. This must be done separately before the main convolutional 
	neural network loader file because I need to manually check if data image is good. Good data 
	means that the square and rectangles are not shifted to the side, the triangles are not so small 
	and that the circles do not overextend the boundary, making the image indecipherable. Then, the 
	200 pixels by 200 pixels cropped image will be feed into the convolutional neural network without 
	the extra preprocessing function in the Keras’ Image Generator. <br>
	<tab2> A typical CPU will not be able to execute a convolutional neural network. The convolutional 
	neural network will be trained in Google Cloud’s virtual machine because a typical job submitted 
	to the Google Cloud gives a memory error if the data input is around 8000 images for training. 
	Increasing the number of GPUs for the job would not work because each GPU is assigned a fixed memory 
	limit for a Google Cloud job. A virtual machine will allow the user to manually install Tensorflow 
	from source. This is because it is very time consuming to train a convolutional neural network. It 
	usually takes about two hours for training. Tensorflow is installed from source, which enables AWX 
	instructions with GPU CUDA support for the Tesla K80. This speeds up the computation of the convolutional
	neural network by three times as without installing Tensorflow from source. Hyperparameter tuning of 
	the dropout layers is an option for the virtual machine to be implemented with Google Cloud’s 
	storage bucket of the project. </p>
	<p> Summary: <br>
	<tab2> During training of the convolutional neural network, the network is not able to go 
	below a loss of 0.38 or reach an accuracy higher than 80% for any epoch. Based on the documentation, 
	the network looks like it is being overfitted because the validation accuracy is lower than the 
	training accuracy. I find that very peculiar and originally thought it was because I was using an 
	incorrect network architecture and loss optimizer for the loss function. I tested on many versions 
	of different network architectures, activation functions and optimizers, but the network still won’t go 
	below 0.38. The major mistake I made was that I assumed I had perfect data images since I made my own data. 
	I didn’t check if the data images are reliable. I had to manually check every training and validation image 
	data to ensure that the data is clear for the neural network to process. After fixing the data images, the 
	training of the convolutional neural network is being underfitted because the validation accuracy is twice 
	as much as the training accuracy and the validation loss is half of the training loss as the first several 
	epochs. This is shown in training output documentation: <br>
   208/207 [==============================] - 62s - loss: 0.8218 - acc: 0.6593 - val_loss: 0.4303 - val_acc: 0.8694 <br>
   <tab2> I tried increasing the layers of the convolutional neural network and reducing the dropout and 
   maxpool layers and it seems to work. The current convolutional neural network architecture is described 
   in the below chart. It also trains in PNG data instead of JPG because the compressed pickled files are much smaller (65MB). </p>
   <p> Adam optimizer of 200 by 200 images (16,000 for training, 1,500 for validation) <br>
   <table>
  <tr>
    <th>Num of filters</th>
    <th>64</th>
    <th>64</th>
    <th> </th>
    <th>64</th>
    <th> </th>
    <th> </th>
    <th> 256 </th>
    <th> 256 </th>
    <th> 256 </th>
    <th> 4 </th>
  </tr>
  <tr>
    <td>Layer Type</td>
    <td>CONV_2D</td>
    <td>CONV_2D</td>
    <td>MAXPOOL</td>
    <td>CONV_2D</td>
    <td>MAXPOOL</td>
    <td>Flatten()</td>
    <td>Dense()</td>
    <td>Dense()</td>
    <td>Dense()</td>
    <td>Dense()</td>
  </tr>
  <tr>
    <td>Conv. Size</td>
    <td>(3,3)</td>
    <td>(6,6)</td>
    <td>(6,6)</td>
    <td>(6,6)</td>
    <td>(6,6)</td>
    <td> </td>
    <td> </td>
    <td>Dropout(0.15)</td>
    <td>Dropout(0.15)</td>
    <td> </td>
  </tr>
  <tr>
    <td>Padding</td>
    <td>valid</td>
    <td>valid</td>
    <td> </td>
    <td>valid</td>
    <td> </td>
    <td> </td>
    <td> </td>
    <td> </td>
    <td> </td>
    <td> </td>
  </tr>
  <tr>
    <td>activation</td>
    <td>relu</td>
    <td>relu</td>
    <td> </td>
    <td>relu</td>
    <td> </td>
    <td> </td>
    <td>relu</td>
    <td>relu</td>
    <td>relu</td>
    <td>softmax</td>
  </tr>
</table></p>
<p> Complete Description of tasks mentioned in the proposal but not accomplished with reasons: <br>
<tab2> Image classification and detection are two separate things in terms of getting 
the code to work. I assumed that they have buildable and very similar architectures, but 
they are completely different. This project only does image classification not image detection 
since image detection requires a recurrent convolutional neural network to be implemented, such 
as the FAST CNN. I am also not able to get the model to generalize well and I am still confused 
about why the model couldn’t learn well. The final code also does not account for intersections 
between shapes as stated in the interim status reports. This is because the loss of the 
convolutional neural network during training wouldn’t go down, so I had to simplify my dataset 
to consist of a single shape per image data instead of two variations of the same shape in an 
image. This is the simplified version of the current dataset and the cropped version of it, 
which is the actual input data for the convolutional neural network. <br>
Evaluation: <p>
<tab2> I think I did considerably well considering that I did not have any prior knowledge 
or experience in machine learning and convolutional neural networks. I had to learn a new 
programming language Python 2.7 and Keras from scratch. I created a program to draw simple 
shapes, my own pickle files to store numpy arrays, merge and load these arrays to prepare 
for the training of the main convolutional neural network file. I did all of this by myself 
without anybody helping me with the code. One of my friends just offered me advice on multiplying 
255 by the float value for the Image module to get the correct background color of the image.
My friend who does Tensorflow gave me a link for a tutorial on compressing image data using 
save from pickle. I had to use joblib to compress the data since it does a great job dumping 
huge lists of numpy image data arrays. That code is not copied, it is a reference within the 
save part, which is roughly five lines of code. In the main convolutional neural network file, 
I had to also use a tutorial on how to prepare the file to be executed in the cloud. The tutorial
is in https://github.com/clintonreece/keras-cloud-ml-engine. <br>
<tab2> I learned that is extremely difficult to get the convolutional neural network to generalize 
well during training. The network is overfitted and underfitted, but that balance is hard to get a 
grasp of. This is because they are so many factors to consider, which are specifically convolutional 
neural network architectures, image input data, loss functions, activation functions, number of filters 
and neurons per layer. I also got a bit sidetracked by trying to do much in the project, classifying 
multi-output labels of intersections between shapes. I should use programs to analyze the image data, 
but the network is too complicated to get important information. This is because it is difficult to 
get the gradients of the hidden layers. </p>

</div>
</div>

</body>
</html>
