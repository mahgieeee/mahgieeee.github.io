"""
Created on Thu Oct 26 20:50:49 2017
Multiprocessing program of independent pool workers uses the Pillow 3 module to 
open PNG image files. The pool workers each individually convert the PNG image 
file to a numpy array of shape (300, 300, 3) where 300 represents the width and
height of the image and 3 represents color format. The image's corresponding 
y_label is generated by doing keras' to_categorical encoding that transforms
integers into different binary 1,0 encoding of classes. These classes are 
circle, rectangle, triangle, and square. The numpy array's total size of 2000 
images per shape is reduced by a half if it's numpy float 16 instead of 
numpy float 32. 
@author: maggie
"""
from __future__ import print_function
from PIL import Image
import glob
import pickle
import numpy as np
from multiprocessing import Lock
from multiprocessing import Pool
from keras.utils import to_categorical

"""to make lock and queue storage global to all child workers in the Pool"""
def init(lock):
    global childs_lock
    childs_lock = lock
    
def process_images(image_path, shape_path):
    shape_y = None
    if shape_path == "resized_images1/circle/":
        shape_y = 0
    if shape_path == "resized_images1/rectangle/": 
        shape_y = 1
    if shape_path == "resized_images1/triangle/":
        shape_y = 2
    if shape_path == "resized_images1/square/":
        shape_y = 3
        
    ylabel = to_categorical(shape_y, num_classes = 4) 
    ylabel = np.reshape(ylabel, (4))
    print ("new shape", ylabel.shape)
    print (ylabel)
    childs_lock.acquire()
    img = Image.open(image_path)
    childs_lock.release()
        
    np_img = np.array(img, dtype = [('img_info', np.float16)]) 
    img.close()
    return np_img['img_info'], ylabel

# global storage variable for both main and pool of workers    
pickle_file = 'circle.pkl'
# create empty pickle_file first then append to file
output = open (pickle_file, 'wb')
output.close()

def result(data):
    output = open (pickle_file, 'ab')
    print ("in pickle file: " , pickle_file)
    pickle.dump(data, output, pickle.HIGHEST_PROTOCOL) 
    output.close()

if __name__ == '__main__':
        
    shape_path = "resized_images1/circle/" 
    lock = Lock()
    p = Pool(processes = 4, initargs = (lock, ), initializer = init)
    
    for image_path in glob.glob(shape_path + "*jpg"):
        p.apply_async(process_images, (image_path, shape_path), callback = result)
    p.close() # no more tasks
    p.join() # wrap up current tasks
    
    
    
    
